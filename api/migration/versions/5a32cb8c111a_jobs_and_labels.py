"""jobs and labels

Revision ID: 5a32cb8c111a
Revises: 1412fd0835fe
Create Date: 2025-07-25 02:18:37.847125

"""

from collections.abc import Sequence
from datetime import datetime
from typing import Any, Union
from uuid import uuid4

import sqlalchemy as sa
from alembic import op
from pydantic import BaseModel
from sqlalchemy.dialects import postgresql


class ReviewSchema(BaseModel):
    title: str | None = None
    username: str | None = None
    rating: float | None = None
    comment: str | None = None
    location: str | None = None
    date: str | None = None
    extra: dict[str, Any] | None = None


# revision identifiers, used by Alembic.
revision: str = "5a32cb8c111a"
down_revision: Union[str, Sequence[str], None] = "1412fd0835fe"
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###

    # 1. Create labels table first
    op.create_table(
        "labels",
        sa.Column("id", sa.UUID(), nullable=False),
        sa.Column("name", sa.String(length=50), nullable=False),
        sa.Column("requirement", sa.Text(), nullable=False),
        sa.Column("output_schema", postgresql.JSONB(astext_type=sa.Text()), nullable=False),
        sa.Column("created_at", sa.DateTime(timezone=True), nullable=False),
        sa.Column("updated_at", sa.DateTime(timezone=True), nullable=False),
        sa.PrimaryKeyConstraint("id"),
        sa.UniqueConstraint("name"),
    )

    # 2. Modify jobs table - drop foreign key first, then add new columns
    op.drop_index(op.f("idx_jobs_output_id"), table_name="jobs")
    op.drop_constraint(op.f("jobs_output_id_fkey"), "jobs", type_="foreignkey")

    # 3. Add new columns to jobs table
    op.add_column("jobs", sa.Column("label_id", sa.UUID(), nullable=True))  # Nullable temporarily
    op.add_column("jobs", sa.Column("source", postgresql.JSONB(astext_type=sa.Text()), nullable=True))
    op.add_column("jobs", sa.Column("usage_count", sa.Integer(), nullable=True))
    op.add_column("jobs", sa.Column("last_used_at", sa.DateTime(timezone=True), nullable=True))
    op.add_column("jobs", sa.Column("error", sa.Text(), nullable=True))
    op.add_column("jobs", sa.Column("initiated_at", sa.DateTime(timezone=True), nullable=False))

    # 4. Now safe to drop outputs table
    op.drop_index(op.f("idx_outputs_popularity"), table_name="outputs")
    op.drop_index(op.f("idx_outputs_tag"), table_name="outputs")
    op.drop_index(op.f("idx_outputs_url_pattern"), table_name="outputs", postgresql_using="gin")
    op.drop_table("outputs")

    # 5. Clean up old columns from jobs
    op.drop_column("jobs", "created_at")
    op.drop_column("jobs", "message")
    op.drop_column("jobs", "output_id")
    op.drop_column("jobs", "tag")

    # 6. Make label_id NOT NULL and add foreign key
    op.alter_column("jobs", "label_id", nullable=False)
    op.create_foreign_key("jobs_label_id_fkey", "jobs", "labels", ["label_id"], ["id"], ondelete="CASCADE")

    # 7. Insert default "reviews" label
    labels_table = sa.table(
        "labels",
        sa.column("id", sa.UUID()),
        sa.column("name", sa.String()),
        sa.column("requirement", sa.Text()),
        sa.column("output_schema", postgresql.JSONB()),
        sa.column("created_at", sa.DateTime()),
        sa.column("updated_at", sa.DateTime()),
    )

    op.bulk_insert(
        labels_table,
        [
            {
                "id": str(uuid4()),
                "name": "reviews",
                "requirement": (
                    "All the user reviews for the product. "
                    "Ignore the summary of the reviews. "
                    "The reviews are typically available as a list of reviews towards the bottom of the page."
                ),
                "output_schema": ReviewSchema.model_json_schema(),
                "created_at": datetime.now(),
                "updated_at": datetime.now(),
            }
        ],
    )
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###

    # 1. Create outputs table first
    op.create_table(
        "outputs",
        sa.Column("id", sa.UUID(), autoincrement=False, nullable=False),
        sa.Column("url", sa.TEXT(), autoincrement=False, nullable=False),
        sa.Column("tag", sa.VARCHAR(length=50), autoincrement=False, nullable=False),
        sa.Column("value", postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=False),
        sa.Column("usage_count", sa.INTEGER(), autoincrement=False, nullable=True),
        sa.Column("last_used_at", postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
        sa.Column("created_at", postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=False),
        sa.Column("updated_at", postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=False),
        sa.PrimaryKeyConstraint("id", name=op.f("outputs_pkey")),
        sa.UniqueConstraint(
            "url",
            "tag",
            name=op.f("outputs_url_tag_unique"),
            postgresql_include=[],
            postgresql_nulls_not_distinct=False,
        ),
    )
    op.create_index(
        op.f("idx_outputs_url_pattern"),
        "outputs",
        [sa.literal_column("to_tsvector('english'::regconfig, url)")],
        unique=False,
        postgresql_using="gin",
    )
    op.create_index(op.f("idx_outputs_tag"), "outputs", ["tag"], unique=False)
    op.create_index(op.f("idx_outputs_popularity"), "outputs", ["usage_count", "last_used_at"], unique=False)

    # 2. Add old columns back to jobs table
    op.add_column("jobs", sa.Column("tag", sa.VARCHAR(length=50), autoincrement=False, nullable=False))
    op.add_column("jobs", sa.Column("output_id", sa.UUID(), autoincrement=False, nullable=True))
    op.add_column("jobs", sa.Column("message", sa.TEXT(), autoincrement=False, nullable=True))
    op.add_column(
        "jobs", sa.Column("created_at", postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=False)
    )

    # 3. Drop foreign key constraint to labels and add foreign key to outputs
    op.drop_constraint("jobs_label_id_fkey", "jobs", type_="foreignkey")
    op.create_foreign_key(op.f("jobs_output_id_fkey"), "jobs", "outputs", ["output_id"], ["id"])
    op.create_index(op.f("idx_jobs_output_id"), "jobs", ["output_id"], unique=False)

    # 4. Drop new columns from jobs table
    op.drop_column("jobs", "initiated_at")
    op.drop_column("jobs", "error")
    op.drop_column("jobs", "last_used_at")
    op.drop_column("jobs", "usage_count")
    op.drop_column("jobs", "source")
    op.drop_column("jobs", "label_id")

    # 5. Drop labels table
    op.drop_table("labels")
    # ### end Alembic commands ###
